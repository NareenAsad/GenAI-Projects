{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ea79750",
   "metadata": {},
   "source": [
    "## **5) Instruction finetuning (part 2; finetuning)**\n",
    "\n",
    "* In this notebook, we get to the actual finetuning part\n",
    "* But first, let's briefly introduce a technique, called LoRA, that makes the finetuning more efficient\n",
    "* It's not required to use LoRA, but it can result in noticeable memory savings while still resulting in good modeling performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb02d8",
   "metadata": {},
   "source": [
    "**5.1 Introduction to LoRA**\n",
    "\n",
    "**Low-Rank Adaptation (LoRA)** is an efficient finetuning technique for large pretrained models.  \n",
    "Instead of updating all model parameters, LoRA introduces two small low-rank matrices that approximate the weight updates.  \n",
    "This drastically reduces the number of trainable parameters, making finetuning faster and more memory-efficient.\n",
    "\n",
    "In standard finetuning, the entire weight matrix \\( W \\) of a model layer is updated.  \n",
    "In LoRA, the update ΔW is represented as the product of two smaller matrices \\( A \\) and \\( B \\):\n",
    "\n",
    "$$\n",
    "\\Delta W = B A\n",
    "$$\n",
    "\n",
    "Thus, the adapted weight becomes:\n",
    "\n",
    "$$\n",
    "W' = W + B A\n",
    "$$\n",
    "\n",
    "This setup allows LoRA to keep the original pretrained weights frozen and apply the low-rank updates dynamically during inference or training.\n",
    "\n",
    "In practice, this means we can efficiently customize large models for specific tasks without retraining or altering the original parameters — ideal for adapting foundation models to new datasets.\n",
    "\n",
    "After setting up the dataset and loading the model, we’ll implement LoRA in code to visualize and apply this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414bb6fd",
   "metadata": {},
   "source": [
    "**5.2 Creating training and test sets**\n",
    "\n",
    "* There's one more thing before we can start finetuning: creating the training and test subsets\n",
    "\n",
    "* We will use 85% of the data for training and the remaining 15% for testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98411ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0385605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.15)    # 15% for testing\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d624f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Test set length: 165\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64528d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.json\", \"w\") as json_file:\n",
    "    json.dump(train_data, json_file, indent=4)\n",
    "    \n",
    "with open(\"test.json\", \"w\") as json_file:\n",
    "    json.dump(test_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471dcf82",
   "metadata": {},
   "source": [
    "**5.3 Instruction finetuning**\n",
    "\n",
    "* Using LitGPT, we can finetune the model via litgpt finetune model_dir\n",
    "\n",
    "* However, here, we will use LoRA finetuning litgpt finetune_lora model_dir since it will be quicker and less resource intensive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b834a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n",
      "Converting checkpoint files to LitGPT format.\n",
      "{'checkpoint_dir': WindowsPath('checkpoints/microsoft/phi-1_5'),\n",
      " 'debug_mode': False,\n",
      " 'dtype': None,\n",
      " 'model_name': None}\n",
      "Saving converted checkpoint to checkpoints\\microsoft\\phi-1_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing  0%|          | 00:00<?, ?it/s\n",
      "Loading weights: model.safetensors:   0%|          | 00:00<?, ?it/s\n",
      "Loading weights: model.safetensors:   0%|          | 00:00<00:56,  1.76it/s\n",
      "Loading weights: model.safetensors:   1%|          | 00:01<03:38,  2.20s/it\n",
      "Loading weights: model.safetensors:   1%|          | 00:02<04:35,  2.78s/it\n",
      "Loading weights: model.safetensors:   3%|▎         | 00:02<01:01,  1.59it/s\n",
      "Loading weights: model.safetensors:   3%|▎         | 00:02<00:49,  1.94it/s\n",
      "Loading weights: model.safetensors:   5%|▍         | 00:02<00:27,  3.42it/s\n",
      "Loading weights: model.safetensors:   6%|▌         | 00:02<00:24,  3.87it/s\n",
      "Loading weights: model.safetensors:   7%|▋         | 00:02<00:19,  4.85it/s\n",
      "Loading weights: model.safetensors:   8%|▊         | 00:03<00:18,  5.07it/s\n",
      "Loading weights: model.safetensors:  10%|▉         | 00:03<00:15,  5.89it/s\n",
      "Loading weights: model.safetensors:  11%|█         | 00:03<00:14,  6.04it/s\n",
      "Loading weights: model.safetensors:  12%|█▏        | 00:03<00:13,  6.58it/s\n",
      "Loading weights: model.safetensors:  13%|█▎        | 00:03<00:14,  6.03it/s\n",
      "Loading weights: model.safetensors:  14%|█▍        | 00:03<00:13,  6.37it/s\n",
      "Loading weights: model.safetensors:  15%|█▌        | 00:04<00:24,  3.43it/s\n",
      "Loading weights: model.safetensors:  16%|█▌        | 00:04<00:24,  3.45it/s\n",
      "Loading weights: model.safetensors:  17%|█▋        | 00:05<00:45,  1.82it/s\n",
      "Loading weights: model.safetensors:  17%|█▋        | 00:06<00:46,  1.77it/s\n",
      "Loading weights: model.safetensors:  19%|█▉        | 00:06<00:31,  2.60it/s\n",
      "Loading weights: model.safetensors:  20%|█▉        | 00:06<00:32,  2.46it/s\n",
      "Loading weights: model.safetensors:  20%|██        | 00:07<00:30,  2.63it/s\n",
      "Loading weights: model.safetensors:  21%|██▏       | 00:08<00:47,  1.66it/s\n",
      "Loading weights: model.safetensors:  22%|██▏       | 00:08<00:47,  1.66it/s\n",
      "Loading weights: model.safetensors:  24%|██▍       | 00:08<00:32,  2.34it/s\n",
      "Loading weights: model.safetensors:  24%|██▍       | 00:09<00:35,  2.12it/s\n",
      "Loading weights: model.safetensors:  26%|██▌       | 00:09<00:24,  3.05it/s\n",
      "Loading weights: model.safetensors:  27%|██▋       | 00:09<00:25,  2.84it/s\n",
      "Loading weights: model.safetensors:  28%|██▊       | 00:10<00:19,  3.69it/s\n",
      "Loading weights: model.safetensors:  29%|██▉       | 00:10<00:21,  3.26it/s\n",
      "Loading weights: model.safetensors:  31%|███       | 00:10<00:15,  4.39it/s\n",
      "Loading weights: model.safetensors:  31%|███▏      | 00:10<00:16,  4.04it/s\n",
      "Loading weights: model.safetensors:  33%|███▎      | 00:11<00:13,  4.80it/s\n",
      "Loading weights: model.safetensors:  34%|███▎      | 00:11<00:15,  4.26it/s\n",
      "Loading weights: model.safetensors:  35%|███▌      | 00:11<00:13,  4.68it/s\n",
      "Loading weights: model.safetensors:  36%|███▌      | 00:11<00:15,  4.11it/s\n",
      "Loading weights: model.safetensors:  37%|███▋      | 00:11<00:15,  4.19it/s\n",
      "Loading weights: model.safetensors:  38%|███▊      | 00:12<00:14,  4.18it/s\n",
      "Loading weights: model.safetensors:  38%|███▊      | 00:12<00:16,  3.73it/s\n",
      "Loading weights: model.safetensors:  40%|████      | 00:12<00:14,  4.27it/s\n",
      "Loading weights: model.safetensors:  41%|████      | 00:13<00:15,  3.77it/s\n",
      "Loading weights: model.safetensors:  43%|████▎     | 00:13<00:12,  4.64it/s\n",
      "Loading weights: model.safetensors:  43%|████▎     | 00:13<00:13,  4.12it/s\n",
      "Loading weights: model.safetensors:  45%|████▍     | 00:14<00:24,  2.21it/s\n",
      "Loading weights: model.safetensors:  45%|████▌     | 00:15<00:25,  2.14it/s\n",
      "Loading weights: model.safetensors:  47%|████▋     | 00:15<00:18,  2.80it/s\n",
      "Loading weights: model.safetensors:  48%|████▊     | 00:15<00:18,  2.89it/s\n",
      "Loading weights: model.safetensors:  50%|████▉     | 00:15<00:12,  3.97it/s\n",
      "Loading weights: model.safetensors:  50%|█████     | 00:16<00:12,  3.89it/s\n",
      "Loading weights: model.safetensors:  51%|█████     | 00:16<00:12,  4.09it/s\n",
      "Loading weights: model.safetensors:  52%|█████▏    | 00:16<00:09,  4.91it/s\n",
      "Loading weights: model.safetensors:  52%|█████▏    | 00:16<00:11,  4.01it/s\n",
      "Loading weights: model.safetensors:  54%|█████▍    | 00:16<00:10,  4.52it/s\n",
      "Loading weights: model.safetensors:  55%|█████▍    | 00:17<00:11,  4.07it/s\n",
      "Loading weights: model.safetensors:  57%|█████▋    | 00:17<00:09,  4.57it/s\n",
      "Loading weights: model.safetensors:  57%|█████▋    | 00:17<00:10,  4.20it/s\n",
      "Loading weights: model.safetensors:  58%|█████▊    | 00:17<00:09,  4.57it/s\n",
      "Loading weights: model.safetensors:  60%|█████▉    | 00:17<00:07,  5.52it/s\n",
      "Loading weights: model.safetensors:  61%|██████    | 00:18<00:06,  6.39it/s\n",
      "Loading weights: model.safetensors:  62%|██████▏   | 00:18<00:05,  7.26it/s\n",
      "Loading weights: model.safetensors:  64%|██████▎   | 00:18<00:04,  8.81it/s\n",
      "Loading weights: model.safetensors:  65%|██████▌   | 00:18<00:03,  9.81it/s\n",
      "Loading weights: model.safetensors:  67%|██████▋   | 00:18<00:03, 10.57it/s\n",
      "Loading weights: model.safetensors:  68%|██████▊   | 00:18<00:03,  9.83it/s\n",
      "Loading weights: model.safetensors:  70%|██████▉   | 00:18<00:03,  9.15it/s\n",
      "Loading weights: model.safetensors:  71%|███████   | 00:19<00:05,  5.08it/s\n",
      "Loading weights: model.safetensors:  72%|███████▏  | 00:19<00:04,  5.94it/s\n",
      "Loading weights: model.safetensors: 100%|██████████| 00:20<00:00, 16.69it/s\n",
      "Loading weights: model.safetensors: 100%|██████████| 00:20<00:00,  4.78it/s\n"
     ]
    }
   ],
   "source": [
    "!litgpt download microsoft/phi-1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3ee5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'access_token': None,\n",
      " 'checkpoint_dir': WindowsPath('checkpoints/microsoft/phi-1_5'),\n",
      " 'data': JSON(json_path=WindowsPath('train.json'),\n",
      "              mask_prompt=False,\n",
      "              val_split_fraction=0.1,\n",
      "              prompt_style=<litgpt.prompts.Alpaca object at 0x000001AF494E5870>,\n",
      "              ignore_index=-100,\n",
      "              seed=42,\n",
      "              num_workers=4),\n",
      " 'devices': 1,\n",
      " 'eval': EvalArgs(interval=100,\n",
      "                  max_new_tokens=100,\n",
      "                  max_iters=100,\n",
      "                  initial_validation=False,\n",
      "                  final_validation=True,\n",
      "                  evaluate_example='first'),\n",
      " 'log': LogArgs(project=None, run=None, group=None),\n",
      " 'logger_name': 'csv',\n",
      " 'lora_alpha': 16,\n",
      " 'lora_dropout': 0.05,\n",
      " 'lora_head': False,\n",
      " 'lora_key': False,\n",
      " 'lora_mlp': False,\n",
      " 'lora_projection': False,\n",
      " 'lora_query': True,\n",
      " 'lora_r': 8,\n",
      " 'lora_value': True,\n",
      " 'num_nodes': 1,\n",
      " 'optimizer': 'AdamW',\n",
      " 'out_dir': WindowsPath('out/finetune/lora'),\n",
      " 'precision': None,\n",
      " 'quantize': None,\n",
      " 'seed': 1337,\n",
      " 'train': TrainArgs(save_interval=1000,\n",
      "                    log_interval=100,\n",
      "                    global_batch_size=16,\n",
      "                    micro_batch_size=1,\n",
      "                    lr_warmup_steps=100,\n",
      "                    lr_warmup_fraction=None,\n",
      "                    epochs=3,\n",
      "                    max_tokens=None,\n",
      "                    max_steps=None,\n",
      "                    max_time=None,\n",
      "                    max_seq_length=None,\n",
      "                    tie_embeddings=None,\n",
      "                    max_norm=None,\n",
      "                    min_lr=6e-05)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "Seed set to 1337\n"
     ]
    }
   ],
   "source": [
    "!litgpt finetune_lora microsoft/phi-1_5 \\\n",
    "--data JSON \\\n",
    "--data.val_split_fraction 0.1 \\\n",
    "--data.json_path train.json \\\n",
    "--train.epochs 3 \\\n",
    "--train.log_interval 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137ea52",
   "metadata": {},
   "source": [
    "## **Exercise 1: Generate and save the test set model responses of the base model**\n",
    "\n",
    "* In this excercise, we are collecting the model responses on the test dataset so that we can evaluate them later\n",
    "\n",
    "* Starting with the original model before finetuning, load the model using the LitGPT Python API (LLM.load ...)\n",
    "\n",
    "* Then use the LLM.generate function to generate the responses for the test data\n",
    "\n",
    "* The following utility function will help you to format the test set entries as input text for the LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f903d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n"
     ]
    }
   ],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text\n",
    "\n",
    "print(format_input(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f06a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litgpt import LLM\n",
    "\n",
    "llm = LLM.load(\"microsoft/phi-1_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995214fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [1:32:28<00:00, 33.62s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    response = llm.generate(test_data[i])\n",
    "    test_data[i][\"base_model\"] = response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12086a9d",
   "metadata": {},
   "source": [
    "- Using this utility function, generate and save all the **test set responses** produced by the model and add them to the `test_set`.\n",
    "\n",
    "- For example, if a `test_data[0]` entry looks like this before:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"instruction\": \"Rewrite the sentence using a simile.\",\n",
    "  \"input\": \"The car is very fast.\",\n",
    "  \"output\": \"The car is as fast as lightning.\"\n",
    "}\n",
    "````\n",
    "\n",
    "* Modify the test data entry so that it includes the **model response** as an additional field (e.g., `\"base_model\"`):\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"instruction\": \"Rewrite the sentence using a simile.\",\n",
    "  \"input\": \"The car is very fast.\",\n",
    "  \"output\": \"The car is as fast as lightning.\",\n",
    "  \"base_model\": \"The car is as fast as a cheetah sprinting across the savannah.\"\n",
    "}\n",
    "```\n",
    "\n",
    "* Repeat this process for **all test set entries**, and then save the modified `test_data` dictionary as:\n",
    "\n",
    "```bash\n",
    "test_base_model.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e336fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'What type of cloud is typically associated with thunderstorms?',\n",
       " 'input': '',\n",
       " 'output': 'The type of cloud typically associated with thunderstorms is cumulonimbus.',\n",
       " 'base_model': '\\ndict1 = {\\'name\\': \\'Python for Beginners\\', \\'instruction\\': \\'Why is Python often referred to as the \\'Go-to\\' programming language?\\', \\'input\\': \\'\\', \\'output\\': \"Python is often referred to'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "649cf84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model responses saved to test_base_model.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_base_model.json\", \"w\") as outfile:\n",
    "    json.dump(test_data, outfile, indent=4)\n",
    "\n",
    "print(\"Base model responses saved to test_base_model.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
