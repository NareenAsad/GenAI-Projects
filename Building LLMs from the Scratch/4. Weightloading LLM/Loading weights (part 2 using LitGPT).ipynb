{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16838710",
   "metadata": {},
   "source": [
    "\n",
    "* Now, we are loading the weights using an open-source library called LitGPT\n",
    "\n",
    "* LitGPT is fundamentally similar to the LLM code we implemented previously, but it is much more sophisticated and supports more than 20 different LLMs (Mistral, Gemma, Llama, Phi, and more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install litgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8e3cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litgpt version: 0.5.11\n",
      "torch version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"litgpt\", \n",
    "        \"torch\",\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c80e1",
   "metadata": {},
   "source": [
    "* First, let's see what LLMs are supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e70508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify --repo_id <repo_id>. Available values:\n",
      "allenai/OLMo-1B-hf\n",
      "allenai/OLMo-2-1124-13B\n",
      "allenai/OLMo-2-1124-13B-DPO\n",
      "allenai/OLMo-2-1124-13B-Instruct\n",
      "allenai/OLMo-2-1124-13B-SFT\n",
      "allenai/OLMo-2-1124-7B\n",
      "allenai/OLMo-2-1124-7B-DPO\n",
      "allenai/OLMo-2-1124-7B-Instruct\n",
      "allenai/OLMo-2-1124-7B-SFT\n",
      "allenai/OLMo-7B-hf\n",
      "allenai/OLMo-7B-Instruct-hf\n",
      "BSC-LT/salamandra-2b\n",
      "BSC-LT/salamandra-2b-instruct\n",
      "BSC-LT/salamandra-7b\n",
      "BSC-LT/salamandra-7b-instruct\n",
      "codellama/CodeLlama-13b-hf\n",
      "codellama/CodeLlama-13b-Instruct-hf\n",
      "codellama/CodeLlama-13b-Python-hf\n",
      "codellama/CodeLlama-34b-hf\n",
      "codellama/CodeLlama-34b-Instruct-hf\n",
      "codellama/CodeLlama-34b-Python-hf\n",
      "codellama/CodeLlama-70b-hf\n",
      "codellama/CodeLlama-70b-Instruct-hf\n",
      "codellama/CodeLlama-70b-Python-hf\n",
      "codellama/CodeLlama-7b-hf\n",
      "codellama/CodeLlama-7b-Instruct-hf\n",
      "codellama/CodeLlama-7b-Python-hf\n",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-70B\n",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n",
      "EleutherAI/pythia-1.4b\n",
      "EleutherAI/pythia-1.4b-deduped\n",
      "EleutherAI/pythia-12b\n",
      "EleutherAI/pythia-12b-deduped\n",
      "EleutherAI/pythia-14m\n",
      "EleutherAI/pythia-160m\n",
      "EleutherAI/pythia-160m-deduped\n",
      "EleutherAI/pythia-1b\n",
      "EleutherAI/pythia-1b-deduped\n",
      "EleutherAI/pythia-2.8b\n",
      "EleutherAI/pythia-2.8b-deduped\n",
      "EleutherAI/pythia-31m\n",
      "EleutherAI/pythia-410m\n",
      "EleutherAI/pythia-410m-deduped\n",
      "EleutherAI/pythia-6.9b\n",
      "EleutherAI/pythia-6.9b-deduped\n",
      "EleutherAI/pythia-70m\n",
      "EleutherAI/pythia-70m-deduped\n",
      "garage-bAInd/Camel-Platypus2-13B\n",
      "garage-bAInd/Camel-Platypus2-70B\n",
      "garage-bAInd/Platypus-30B\n",
      "garage-bAInd/Platypus2-13B\n",
      "garage-bAInd/Platypus2-70B\n",
      "garage-bAInd/Platypus2-70B-instruct\n",
      "garage-bAInd/Platypus2-7B\n",
      "garage-bAInd/Stable-Platypus2-13B\n",
      "google/codegemma-7b-it\n",
      "google/gemma-2-27b\n",
      "google/gemma-2-27b-it\n",
      "google/gemma-2-2b\n",
      "google/gemma-2-2b-it\n",
      "google/gemma-2-9b\n",
      "google/gemma-2-9b-it\n",
      "google/gemma-2b\n",
      "google/gemma-2b-it\n",
      "google/gemma-3-12b-it\n",
      "google/gemma-3-1b-it\n",
      "google/gemma-3-27b-it\n",
      "google/gemma-3-4b-it\n",
      "google/gemma-7b\n",
      "google/gemma-7b-it\n",
      "HuggingFaceTB/SmolLM2-1.7B\n",
      "HuggingFaceTB/SmolLM2-1.7B-Instruct\n",
      "HuggingFaceTB/SmolLM2-135M\n",
      "HuggingFaceTB/SmolLM2-135M-Instruct\n",
      "HuggingFaceTB/SmolLM2-360M\n",
      "HuggingFaceTB/SmolLM2-360M-Instruct\n",
      "keeeeenw/MicroLlama\n",
      "meta-llama/Llama-2-13b-chat-hf\n",
      "meta-llama/Llama-2-13b-hf\n",
      "meta-llama/Llama-2-70b-chat-hf\n",
      "meta-llama/Llama-2-70b-hf\n",
      "meta-llama/Llama-2-7b-chat-hf\n",
      "meta-llama/Llama-2-7b-hf\n",
      "meta-llama/Llama-3.2-1B\n",
      "meta-llama/Llama-3.2-1B-Instruct\n",
      "meta-llama/Llama-3.2-3B\n",
      "meta-llama/Llama-3.2-3B-Instruct\n",
      "meta-llama/Llama-3.3-70B-Instruct\n",
      "meta-llama/Meta-Llama-3-70B\n",
      "meta-llama/Meta-Llama-3-70B-Instruct\n",
      "meta-llama/Meta-Llama-3-8B\n",
      "meta-llama/Meta-Llama-3-8B-Instruct\n",
      "meta-llama/Meta-Llama-3.1-405B\n",
      "meta-llama/Meta-Llama-3.1-405B-Instruct\n",
      "meta-llama/Meta-Llama-3.1-70B\n",
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "meta-llama/Meta-Llama-3.1-8B\n",
      "meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "microsoft/phi-1_5\n",
      "microsoft/phi-2\n",
      "microsoft/Phi-3-mini-128k-instruct\n",
      "microsoft/Phi-3-mini-4k-instruct\n",
      "microsoft/Phi-3.5-mini-instruct\n",
      "microsoft/phi-4\n",
      "microsoft/Phi-4-mini-instruct\n",
      "microsoft/Phi-4-mini-reasoning\n",
      "microsoft/Phi-4-reasoning\n",
      "microsoft/Phi-4-reasoning-plus\n",
      "mistralai/mathstral-7B-v0.1\n",
      "mistralai/Mistral-7B-Instruct-v0.1\n",
      "mistralai/Mistral-7B-Instruct-v0.2\n",
      "mistralai/Mistral-7B-Instruct-v0.3\n",
      "mistralai/Mistral-7B-v0.1\n",
      "mistralai/Mistral-7B-v0.3\n",
      "mistralai/Mistral-Large-Instruct-2407\n",
      "mistralai/Mistral-Large-Instruct-2411\n",
      "mistralai/Mixtral-8x22B-Instruct-v0.1\n",
      "mistralai/Mixtral-8x22B-v0.1\n",
      "mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "mistralai/Mixtral-8x7B-v0.1\n",
      "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\n",
      "openlm-research/open_llama_13b\n",
      "openlm-research/open_llama_3b\n",
      "openlm-research/open_llama_7b\n",
      "Qwen/Qwen2.5-0.5B\n",
      "Qwen/Qwen2.5-0.5B-Instruct\n",
      "Qwen/Qwen2.5-1.5B\n",
      "Qwen/Qwen2.5-1.5B-Instruct\n",
      "Qwen/Qwen2.5-14B\n",
      "Qwen/Qwen2.5-14B-Instruct\n",
      "Qwen/Qwen2.5-14B-Instruct-1M\n",
      "Qwen/Qwen2.5-32B\n",
      "Qwen/Qwen2.5-32B-Instruct\n",
      "Qwen/Qwen2.5-3B\n",
      "Qwen/Qwen2.5-3B-Instruct\n",
      "Qwen/Qwen2.5-72B\n",
      "Qwen/Qwen2.5-72B-Instruct\n",
      "Qwen/Qwen2.5-7B\n",
      "Qwen/Qwen2.5-7B-Instruct\n",
      "Qwen/Qwen2.5-7B-Instruct-1M\n",
      "Qwen/Qwen2.5-Coder-0.5B\n",
      "Qwen/Qwen2.5-Coder-0.5B-Instruct\n",
      "Qwen/Qwen2.5-Coder-1.5B\n",
      "Qwen/Qwen2.5-Coder-1.5B-Instruct\n",
      "Qwen/Qwen2.5-Coder-14B\n",
      "Qwen/Qwen2.5-Coder-14B-Instruct\n",
      "Qwen/Qwen2.5-Coder-32B\n",
      "Qwen/Qwen2.5-Coder-32B-Instruct\n",
      "Qwen/Qwen2.5-Coder-3B\n",
      "Qwen/Qwen2.5-Coder-3B-Instruct\n",
      "Qwen/Qwen2.5-Coder-7B\n",
      "Qwen/Qwen2.5-Coder-7B-Instruct\n",
      "Qwen/Qwen2.5-Math-1.5B\n",
      "Qwen/Qwen2.5-Math-1.5B-Instruct\n",
      "Qwen/Qwen2.5-Math-72B\n",
      "Qwen/Qwen2.5-Math-72B-Instruct\n",
      "Qwen/Qwen2.5-Math-7B\n",
      "Qwen/Qwen2.5-Math-7B-Instruct\n",
      "Qwen/Qwen3-0.6B\n",
      "Qwen/Qwen3-0.6B-Base\n",
      "Qwen/Qwen3-1.7B\n",
      "Qwen/Qwen3-1.7B-Base\n",
      "Qwen/Qwen3-14B\n",
      "Qwen/Qwen3-14B-Base\n",
      "Qwen/Qwen3-235B-A22B\n",
      "Qwen/Qwen3-235B-A22B-Instruct-2507\n",
      "Qwen/Qwen3-235B-A22B-Thinking-2507\n",
      "Qwen/Qwen3-30B-A3B\n",
      "Qwen/Qwen3-30B-A3B-Base\n",
      "Qwen/Qwen3-30B-A3B-Instruct-2507\n",
      "Qwen/Qwen3-30B-A3B-Thinking-2507\n",
      "Qwen/Qwen3-32B\n",
      "Qwen/Qwen3-4B\n",
      "Qwen/Qwen3-4B-Base\n",
      "Qwen/Qwen3-4B-Instruct-2507\n",
      "Qwen/Qwen3-4B-Thinking-2507\n",
      "Qwen/Qwen3-8B\n",
      "Qwen/Qwen3-8B-Base\n",
      "Qwen/QwQ-32B\n",
      "Qwen/QwQ-32B-Preview\n",
      "stabilityai/FreeWilly2\n",
      "stabilityai/stable-code-3b\n",
      "stabilityai/stablecode-completion-alpha-3b\n",
      "stabilityai/stablecode-completion-alpha-3b-4k\n",
      "stabilityai/stablecode-instruct-alpha-3b\n",
      "stabilityai/stablelm-3b-4e1t\n",
      "stabilityai/stablelm-base-alpha-3b\n",
      "stabilityai/stablelm-base-alpha-7b\n",
      "stabilityai/stablelm-tuned-alpha-3b\n",
      "stabilityai/stablelm-tuned-alpha-7b\n",
      "stabilityai/stablelm-zephyr-3b\n",
      "tiiuae/falcon-180B\n",
      "tiiuae/falcon-180B-chat\n",
      "tiiuae/falcon-40b\n",
      "tiiuae/falcon-40b-instruct\n",
      "tiiuae/falcon-7b\n",
      "tiiuae/falcon-7b-instruct\n",
      "tiiuae/Falcon3-10B-Base\n",
      "tiiuae/Falcon3-10B-Instruct\n",
      "tiiuae/Falcon3-1B-Base\n",
      "tiiuae/Falcon3-1B-Instruct\n",
      "tiiuae/Falcon3-3B-Base\n",
      "tiiuae/Falcon3-3B-Instruct\n",
      "tiiuae/Falcon3-7B-Base\n",
      "tiiuae/Falcon3-7B-Instruct\n",
      "TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\n",
      "togethercomputer/LLaMA-2-7B-32K\n",
      "Trelis/Llama-2-7b-chat-hf-function-calling-v2\n",
      "unsloth/Mistral-7B-v0.2\n"
     ]
    }
   ],
   "source": [
    "!litgpt download list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d7a507",
   "metadata": {},
   "source": [
    "\n",
    "* We can then download an LLM via the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cac6cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting HF_HUB_ENABLE_HF_TRANSFER=1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing  0%|          | 00:00<?, ?it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   0%|          | 00:00<?, ?it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   0%|          | 00:01<09:19,  5.60s/it\n",
      "Loading weights: model-00001-of-00002.safetensors:   1%|          | 00:01<01:41,  1.02s/it\n",
      "Loading weights: model-00001-of-00002.safetensors:   1%|▏         | 00:01<01:21,  1.21it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   3%|▎         | 00:01<00:45,  2.13it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   3%|▎         | 00:02<00:49,  1.95it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   4%|▍         | 00:02<00:37,  2.54it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   5%|▍         | 00:02<00:43,  2.19it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   6%|▌         | 00:03<00:38,  2.47it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   7%|▋         | 00:03<00:43,  2.16it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   8%|▊         | 00:03<00:34,  2.63it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:   8%|▊         | 00:04<00:40,  2.28it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  10%|▉         | 00:04<00:32,  2.78it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  10%|▉         | 00:04<00:36,  2.48it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  11%|█▏        | 00:05<00:29,  2.97it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  12%|█▏        | 00:05<00:33,  2.61it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  13%|█▎        | 00:05<00:27,  3.15it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  13%|█▎        | 00:05<00:31,  2.77it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  15%|█▍        | 00:06<00:25,  3.31it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  15%|█▌        | 00:06<00:29,  2.83it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  16%|█▋        | 00:06<00:23,  3.51it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  17%|█▋        | 00:06<00:26,  3.09it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  18%|█▊        | 00:07<00:24,  3.40it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  18%|█▊        | 00:07<00:28,  2.85it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  20%|█▉        | 00:07<00:24,  3.31it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  20%|██        | 00:08<00:28,  2.79it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  21%|██▏       | 00:08<00:24,  3.21it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  22%|██▏       | 00:08<00:28,  2.71it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  23%|██▎       | 00:08<00:22,  3.42it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  24%|██▎       | 00:09<00:26,  2.87it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  25%|██▍       | 00:09<00:25,  2.96it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  25%|██▌       | 00:09<00:27,  2.68it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  27%|██▋       | 00:10<00:21,  3.39it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  27%|██▋       | 00:10<00:22,  3.18it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  28%|██▊       | 00:10<00:19,  3.59it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  29%|██▊       | 00:10<00:22,  3.16it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  30%|██▉       | 00:11<00:18,  3.73it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  30%|███       | 00:11<00:20,  3.33it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  32%|███▏      | 00:11<00:18,  3.65it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  32%|███▏      | 00:11<00:21,  3.17it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  33%|███▎      | 00:11<00:17,  3.80it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  34%|███▍      | 00:12<00:20,  3.27it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  35%|███▌      | 00:12<00:17,  3.63it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  35%|███▌      | 00:12<00:20,  3.17it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  37%|███▋      | 00:13<00:35,  1.76it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  37%|███▋      | 00:14<00:45,  1.38it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  38%|███▊      | 00:15<00:38,  1.58it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  39%|███▉      | 00:15<00:39,  1.53it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  40%|████      | 00:15<00:27,  2.16it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  41%|████      | 00:16<00:39,  1.52it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  41%|████      | 00:16<00:42,  1.38it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  42%|████▏     | 00:18<00:56,  1.04it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  42%|████▏     | 00:19<01:18,  1.37s/it\n",
      "Loading weights: model-00001-of-00002.safetensors:  44%|████▎     | 00:19<00:53,  1.05it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  44%|████▍     | 00:20<00:56,  1.01s/it\n",
      "Loading weights: model-00001-of-00002.safetensors:  45%|████▌     | 00:21<00:44,  1.22it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  46%|████▌     | 00:21<00:47,  1.13it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  46%|████▌     | 00:22<00:48,  1.12it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  47%|████▋     | 00:22<00:37,  1.40it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  47%|████▋     | 00:22<00:37,  1.42it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  49%|████▊     | 00:23<00:26,  1.97it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  49%|████▉     | 00:23<00:29,  1.75it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  50%|█████     | 00:23<00:21,  2.27it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  51%|█████     | 00:24<00:24,  2.00it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  51%|█████     | 00:24<00:22,  2.16it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  52%|█████▏    | 00:24<00:17,  2.81it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  53%|█████▎    | 00:24<00:13,  3.47it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  54%|█████▎    | 00:24<00:11,  4.12it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  55%|█████▍    | 00:24<00:10,  4.45it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  55%|█████▌    | 00:24<00:09,  4.82it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  56%|█████▋    | 00:25<00:08,  5.40it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  57%|█████▋    | 00:25<00:07,  5.71it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  58%|█████▊    | 00:25<00:07,  5.75it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  59%|█████▉    | 00:25<00:07,  5.38it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  59%|█████▉    | 00:25<00:07,  5.17it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  60%|██████    | 00:25<00:10,  3.98it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  61%|██████    | 00:26<00:09,  4.10it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  61%|██████▏   | 00:26<00:09,  4.08it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  62%|██████▏   | 00:26<00:08,  4.50it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  63%|██████▎   | 00:26<00:07,  4.77it/s\n",
      "Loading weights: model-00001-of-00002.safetensors:  64%|██████▍   | 00:26<00:07,  5.01it/s\n",
      "Loading weights: model-00002-of-00002.safetensors:  64%|██████▍   | 00:26<00:07,  5.01it/s\n",
      "Loading weights: model-00002-of-00002.safetensors:  65%|██████▍   | 00:28<00:29,  1.21it/s\n",
      "Loading weights: model-00002-of-00002.safetensors:  65%|██████▌   | 00:28<00:25,  1.38it/s\n",
      "Loading weights: model-00002-of-00002.safetensors:  66%|██████▌   | 00:29<00:25,  1.34it/s\n",
      "Loading weights: model-00002-of-00002.safetensors:  66%|██████▌   | 00:29<00:22,  1.49it/s\n",
      "Loading weights: model-00002-of-00002.safetensors:  67%|██████▋   | 00:29<00:19,  1.70it/s\n",
      "Loading weights: model-00002-of-00002.safetensors:  67%|██████▋   | 00:29<00:23,  1.40it/s\n",
      "Loading weights: model-00002-of-00002.safetensors:  68%|██████▊   | 00:30<00:18,  1.77it/s\n",
      "Loading weights: model-00002-of-00002.safetensors:  68%|██████▊   | 00:30<00:29,  1.07it/s\n",
      "Loading weights: model-00002-of-00002.safetensors: 100%|██████████| 00:31<00:00, 18.84it/s\n",
      "Loading weights: model-00002-of-00002.safetensors: 100%|██████████| 00:31<00:00,  3.17it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting checkpoint files to LitGPT format.\n",
      "{'checkpoint_dir': WindowsPath('checkpoints/microsoft/phi-2'),\n",
      " 'debug_mode': False,\n",
      " 'dtype': None,\n",
      " 'model_name': None}\n",
      "Saving converted checkpoint to checkpoints\\microsoft\\phi-2\n"
     ]
    }
   ],
   "source": [
    "!litgpt download microsoft/phi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447ebf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naree\\miniforge3\\envs\\LLMs\\lib\\site-packages\\litgpt\\utils.py:699: UserWarning: The file size of checkpoints\\microsoft\\phi-2\\lit_model.pth is over 4.2 GB. Using a model with more than 1B parameters on a CPU can be slow, it is recommended to switch to a GPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Llamas are herbivores and mainly feed on grass, leaves, and shrubs. They have a tough digestive system that allows them to consume a variety of plant materials.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from litgpt import LLM\n",
    "\n",
    "llm = LLM.load(\"microsoft/phi-2\")\n",
    "\n",
    "llm.generate(\"What do Llamas eat?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c637373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Teak.\n"
     ]
    }
   ],
   "source": [
    "result = llm.generate(\"What do Llamas eat?\", stream=True, max_new_tokens=200)\n",
    "for e in result:\n",
    "    print(e, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be061a0f",
   "metadata": {},
   "source": [
    "**Exercise 2: Download an LLM**\n",
    "\n",
    "* Download and try out an LLM of your own choice (recommendation: 7B parameters or smaller)\n",
    "\n",
    "* We will finetune the LLM in the next notebook\n",
    "\n",
    "* You can also try out the litgpt chat command from the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ddb039",
   "metadata": {},
   "source": [
    "Step 1. Install LitGPT and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install litgpt torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744e7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litgpt version: 0.5.11\n",
      "torch version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "for p in [\"litgpt\", \"torch\"]:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff62ec5",
   "metadata": {},
   "source": [
    "Step 2. See Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2212394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify --repo_id <repo_id>. Available values:\n",
      "allenai/OLMo-1B-hf\n",
      "allenai/OLMo-2-1124-13B\n",
      "allenai/OLMo-2-1124-13B-DPO\n",
      "allenai/OLMo-2-1124-13B-Instruct\n",
      "allenai/OLMo-2-1124-13B-SFT\n",
      "allenai/OLMo-2-1124-7B\n",
      "allenai/OLMo-2-1124-7B-DPO\n",
      "allenai/OLMo-2-1124-7B-Instruct\n",
      "allenai/OLMo-2-1124-7B-SFT\n",
      "allenai/OLMo-7B-hf\n",
      "allenai/OLMo-7B-Instruct-hf\n",
      "BSC-LT/salamandra-2b\n",
      "BSC-LT/salamandra-2b-instruct\n",
      "BSC-LT/salamandra-7b\n",
      "BSC-LT/salamandra-7b-instruct\n",
      "codellama/CodeLlama-13b-hf\n",
      "codellama/CodeLlama-13b-Instruct-hf\n",
      "codellama/CodeLlama-13b-Python-hf\n",
      "codellama/CodeLlama-34b-hf\n",
      "codellama/CodeLlama-34b-Instruct-hf\n",
      "codellama/CodeLlama-34b-Python-hf\n",
      "codellama/CodeLlama-70b-hf\n",
      "codellama/CodeLlama-70b-Instruct-hf\n",
      "codellama/CodeLlama-70b-Python-hf\n",
      "codellama/CodeLlama-7b-hf\n",
      "codellama/CodeLlama-7b-Instruct-hf\n",
      "codellama/CodeLlama-7b-Python-hf\n",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-70B\n",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n",
      "EleutherAI/pythia-1.4b\n",
      "EleutherAI/pythia-1.4b-deduped\n",
      "EleutherAI/pythia-12b\n",
      "EleutherAI/pythia-12b-deduped\n",
      "EleutherAI/pythia-14m\n",
      "EleutherAI/pythia-160m\n",
      "EleutherAI/pythia-160m-deduped\n",
      "EleutherAI/pythia-1b\n",
      "EleutherAI/pythia-1b-deduped\n",
      "EleutherAI/pythia-2.8b\n",
      "EleutherAI/pythia-2.8b-deduped\n",
      "EleutherAI/pythia-31m\n",
      "EleutherAI/pythia-410m\n",
      "EleutherAI/pythia-410m-deduped\n",
      "EleutherAI/pythia-6.9b\n",
      "EleutherAI/pythia-6.9b-deduped\n",
      "EleutherAI/pythia-70m\n",
      "EleutherAI/pythia-70m-deduped\n",
      "garage-bAInd/Camel-Platypus2-13B\n",
      "garage-bAInd/Camel-Platypus2-70B\n",
      "garage-bAInd/Platypus-30B\n",
      "garage-bAInd/Platypus2-13B\n",
      "garage-bAInd/Platypus2-70B\n",
      "garage-bAInd/Platypus2-70B-instruct\n",
      "garage-bAInd/Platypus2-7B\n",
      "garage-bAInd/Stable-Platypus2-13B\n",
      "google/codegemma-7b-it\n",
      "google/gemma-2-27b\n",
      "google/gemma-2-27b-it\n",
      "google/gemma-2-2b\n",
      "google/gemma-2-2b-it\n",
      "google/gemma-2-9b\n",
      "google/gemma-2-9b-it\n",
      "google/gemma-2b\n",
      "google/gemma-2b-it\n",
      "google/gemma-3-12b-it\n",
      "google/gemma-3-1b-it\n",
      "google/gemma-3-27b-it\n",
      "google/gemma-3-4b-it\n",
      "google/gemma-7b\n",
      "google/gemma-7b-it\n",
      "HuggingFaceTB/SmolLM2-1.7B\n",
      "HuggingFaceTB/SmolLM2-1.7B-Instruct\n",
      "HuggingFaceTB/SmolLM2-135M\n",
      "HuggingFaceTB/SmolLM2-135M-Instruct\n",
      "HuggingFaceTB/SmolLM2-360M\n",
      "HuggingFaceTB/SmolLM2-360M-Instruct\n",
      "keeeeenw/MicroLlama\n",
      "meta-llama/Llama-2-13b-chat-hf\n",
      "meta-llama/Llama-2-13b-hf\n",
      "meta-llama/Llama-2-70b-chat-hf\n",
      "meta-llama/Llama-2-70b-hf\n",
      "meta-llama/Llama-2-7b-chat-hf\n",
      "meta-llama/Llama-2-7b-hf\n",
      "meta-llama/Llama-3.2-1B\n",
      "meta-llama/Llama-3.2-1B-Instruct\n",
      "meta-llama/Llama-3.2-3B\n",
      "meta-llama/Llama-3.2-3B-Instruct\n",
      "meta-llama/Llama-3.3-70B-Instruct\n",
      "meta-llama/Meta-Llama-3-70B\n",
      "meta-llama/Meta-Llama-3-70B-Instruct\n",
      "meta-llama/Meta-Llama-3-8B\n",
      "meta-llama/Meta-Llama-3-8B-Instruct\n",
      "meta-llama/Meta-Llama-3.1-405B\n",
      "meta-llama/Meta-Llama-3.1-405B-Instruct\n",
      "meta-llama/Meta-Llama-3.1-70B\n",
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "meta-llama/Meta-Llama-3.1-8B\n",
      "meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "microsoft/phi-1_5\n",
      "microsoft/phi-2\n",
      "microsoft/Phi-3-mini-128k-instruct\n",
      "microsoft/Phi-3-mini-4k-instruct\n",
      "microsoft/Phi-3.5-mini-instruct\n",
      "microsoft/phi-4\n",
      "microsoft/Phi-4-mini-instruct\n",
      "microsoft/Phi-4-mini-reasoning\n",
      "microsoft/Phi-4-reasoning\n",
      "microsoft/Phi-4-reasoning-plus\n",
      "mistralai/mathstral-7B-v0.1\n",
      "mistralai/Mistral-7B-Instruct-v0.1\n",
      "mistralai/Mistral-7B-Instruct-v0.2\n",
      "mistralai/Mistral-7B-Instruct-v0.3\n",
      "mistralai/Mistral-7B-v0.1\n",
      "mistralai/Mistral-7B-v0.3\n",
      "mistralai/Mistral-Large-Instruct-2407\n",
      "mistralai/Mistral-Large-Instruct-2411\n",
      "mistralai/Mixtral-8x22B-Instruct-v0.1\n",
      "mistralai/Mixtral-8x22B-v0.1\n",
      "mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "mistralai/Mixtral-8x7B-v0.1\n",
      "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\n",
      "openlm-research/open_llama_13b\n",
      "openlm-research/open_llama_3b\n",
      "openlm-research/open_llama_7b\n",
      "Qwen/Qwen2.5-0.5B\n",
      "Qwen/Qwen2.5-0.5B-Instruct\n",
      "Qwen/Qwen2.5-1.5B\n",
      "Qwen/Qwen2.5-1.5B-Instruct\n",
      "Qwen/Qwen2.5-14B\n",
      "Qwen/Qwen2.5-14B-Instruct\n",
      "Qwen/Qwen2.5-14B-Instruct-1M\n",
      "Qwen/Qwen2.5-32B\n",
      "Qwen/Qwen2.5-32B-Instruct\n",
      "Qwen/Qwen2.5-3B\n",
      "Qwen/Qwen2.5-3B-Instruct\n",
      "Qwen/Qwen2.5-72B\n",
      "Qwen/Qwen2.5-72B-Instruct\n",
      "Qwen/Qwen2.5-7B\n",
      "Qwen/Qwen2.5-7B-Instruct\n",
      "Qwen/Qwen2.5-7B-Instruct-1M\n",
      "Qwen/Qwen2.5-Coder-0.5B\n",
      "Qwen/Qwen2.5-Coder-0.5B-Instruct\n",
      "Qwen/Qwen2.5-Coder-1.5B\n",
      "Qwen/Qwen2.5-Coder-1.5B-Instruct\n",
      "Qwen/Qwen2.5-Coder-14B\n",
      "Qwen/Qwen2.5-Coder-14B-Instruct\n",
      "Qwen/Qwen2.5-Coder-32B\n",
      "Qwen/Qwen2.5-Coder-32B-Instruct\n",
      "Qwen/Qwen2.5-Coder-3B\n",
      "Qwen/Qwen2.5-Coder-3B-Instruct\n",
      "Qwen/Qwen2.5-Coder-7B\n",
      "Qwen/Qwen2.5-Coder-7B-Instruct\n",
      "Qwen/Qwen2.5-Math-1.5B\n",
      "Qwen/Qwen2.5-Math-1.5B-Instruct\n",
      "Qwen/Qwen2.5-Math-72B\n",
      "Qwen/Qwen2.5-Math-72B-Instruct\n",
      "Qwen/Qwen2.5-Math-7B\n",
      "Qwen/Qwen2.5-Math-7B-Instruct\n",
      "Qwen/Qwen3-0.6B\n",
      "Qwen/Qwen3-0.6B-Base\n",
      "Qwen/Qwen3-1.7B\n",
      "Qwen/Qwen3-1.7B-Base\n",
      "Qwen/Qwen3-14B\n",
      "Qwen/Qwen3-14B-Base\n",
      "Qwen/Qwen3-235B-A22B\n",
      "Qwen/Qwen3-235B-A22B-Instruct-2507\n",
      "Qwen/Qwen3-235B-A22B-Thinking-2507\n",
      "Qwen/Qwen3-30B-A3B\n",
      "Qwen/Qwen3-30B-A3B-Base\n",
      "Qwen/Qwen3-30B-A3B-Instruct-2507\n",
      "Qwen/Qwen3-30B-A3B-Thinking-2507\n",
      "Qwen/Qwen3-32B\n",
      "Qwen/Qwen3-4B\n",
      "Qwen/Qwen3-4B-Base\n",
      "Qwen/Qwen3-4B-Instruct-2507\n",
      "Qwen/Qwen3-4B-Thinking-2507\n",
      "Qwen/Qwen3-8B\n",
      "Qwen/Qwen3-8B-Base\n",
      "Qwen/QwQ-32B\n",
      "Qwen/QwQ-32B-Preview\n",
      "stabilityai/FreeWilly2\n",
      "stabilityai/stable-code-3b\n",
      "stabilityai/stablecode-completion-alpha-3b\n",
      "stabilityai/stablecode-completion-alpha-3b-4k\n",
      "stabilityai/stablecode-instruct-alpha-3b\n",
      "stabilityai/stablelm-3b-4e1t\n",
      "stabilityai/stablelm-base-alpha-3b\n",
      "stabilityai/stablelm-base-alpha-7b\n",
      "stabilityai/stablelm-tuned-alpha-3b\n",
      "stabilityai/stablelm-tuned-alpha-7b\n",
      "stabilityai/stablelm-zephyr-3b\n",
      "tiiuae/falcon-180B\n",
      "tiiuae/falcon-180B-chat\n",
      "tiiuae/falcon-40b\n",
      "tiiuae/falcon-40b-instruct\n",
      "tiiuae/falcon-7b\n",
      "tiiuae/falcon-7b-instruct\n",
      "tiiuae/Falcon3-10B-Base\n",
      "tiiuae/Falcon3-10B-Instruct\n",
      "tiiuae/Falcon3-1B-Base\n",
      "tiiuae/Falcon3-1B-Instruct\n",
      "tiiuae/Falcon3-3B-Base\n",
      "tiiuae/Falcon3-3B-Instruct\n",
      "tiiuae/Falcon3-7B-Base\n",
      "tiiuae/Falcon3-7B-Instruct\n",
      "TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\n",
      "togethercomputer/LLaMA-2-7B-32K\n",
      "Trelis/Llama-2-7b-chat-hf-function-calling-v2\n",
      "unsloth/Mistral-7B-v0.2\n"
     ]
    }
   ],
   "source": [
    "!litgpt download list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161793f",
   "metadata": {},
   "source": [
    "Step 3. Download a Model\n",
    "\n",
    "* (recommendation: 7B parameters or smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ed5766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n",
      "Converting checkpoint files to LitGPT format.\n",
      "{'checkpoint_dir': WindowsPath('checkpoints/microsoft/phi-1_5'),\n",
      " 'debug_mode': False,\n",
      " 'dtype': None,\n",
      " 'model_name': None}\n",
      "Saving converted checkpoint to checkpoints\\microsoft\\phi-1_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing  0%|          | 00:00<?, ?it/s\n",
      "Loading weights: model.safetensors:   0%|          | 00:00<?, ?it/s\n",
      "Loading weights: model.safetensors:   0%|          | 00:00<01:03,  1.58it/s\n",
      "Loading weights: model.safetensors:   1%|          | 00:02<08:34,  5.18s/it\n",
      "Loading weights: model.safetensors:   1%|          | 00:03<07:47,  4.72s/it\n",
      "Loading weights: model.safetensors:   1%|          | 00:04<05:48,  3.52s/it\n",
      "Loading weights: model.safetensors:   3%|▎         | 00:04<01:38,  1.01s/it\n",
      "Loading weights: model.safetensors:   3%|▎         | 00:04<01:17,  1.25it/s\n",
      "Loading weights: model.safetensors:   4%|▍         | 00:04<00:51,  1.87it/s\n",
      "Loading weights: model.safetensors:   5%|▍         | 00:04<00:38,  2.44it/s\n",
      "Loading weights: model.safetensors:   6%|▌         | 00:05<00:36,  2.57it/s\n",
      "Loading weights: model.safetensors:   7%|▋         | 00:05<00:23,  3.96it/s\n",
      "Loading weights: model.safetensors:   8%|▊         | 00:05<00:24,  3.71it/s\n",
      "Loading weights: model.safetensors:   9%|▊         | 00:05<00:29,  3.15it/s\n",
      "Loading weights: model.safetensors:  10%|▉         | 00:06<00:32,  2.78it/s\n",
      "Loading weights: model.safetensors:  10%|█         | 00:07<01:16,  1.17it/s\n",
      "Loading weights: model.safetensors:  12%|█▏        | 00:08<00:47,  1.86it/s\n",
      "Loading weights: model.safetensors:  13%|█▎        | 00:08<00:56,  1.54it/s\n",
      "Loading weights: model.safetensors:  14%|█▍        | 00:09<00:37,  2.29it/s\n",
      "Loading weights: model.safetensors:  15%|█▍        | 00:10<01:06,  1.28it/s\n",
      "Loading weights: model.safetensors:  17%|█▋        | 00:10<00:43,  1.91it/s\n",
      "Loading weights: model.safetensors:  17%|█▋        | 00:11<00:41,  1.99it/s\n",
      "Loading weights: model.safetensors:  19%|█▉        | 00:11<00:29,  2.75it/s\n",
      "Loading weights: model.safetensors:  20%|█▉        | 00:11<00:32,  2.48it/s\n",
      "Loading weights: model.safetensors:  21%|██▏       | 00:12<00:22,  3.42it/s\n",
      "Loading weights: model.safetensors:  22%|██▏       | 00:12<00:24,  3.17it/s\n",
      "Loading weights: model.safetensors:  23%|██▎       | 00:12<00:24,  3.15it/s\n",
      "Loading weights: model.safetensors:  24%|██▍       | 00:12<00:20,  3.81it/s\n",
      "Loading weights: model.safetensors:  24%|██▍       | 00:12<00:22,  3.34it/s\n",
      "Loading weights: model.safetensors:  25%|██▍       | 00:13<00:21,  3.48it/s\n",
      "Loading weights: model.safetensors:  26%|██▌       | 00:13<00:20,  3.69it/s\n",
      "Loading weights: model.safetensors:  27%|██▋       | 00:13<00:27,  2.66it/s\n",
      "Loading weights: model.safetensors:  28%|██▊       | 00:14<00:19,  3.62it/s\n",
      "Loading weights: model.safetensors:  29%|██▉       | 00:14<00:21,  3.24it/s\n",
      "Loading weights: model.safetensors:  31%|███       | 00:14<00:19,  3.52it/s\n",
      "Loading weights: model.safetensors:  31%|███▏      | 00:15<00:20,  3.42it/s\n",
      "Loading weights: model.safetensors:  33%|███▎      | 00:15<00:17,  3.79it/s\n",
      "Loading weights: model.safetensors:  34%|███▎      | 00:15<00:21,  3.15it/s\n",
      "Loading weights: model.safetensors:  35%|███▌      | 00:16<00:15,  4.04it/s\n",
      "Loading weights: model.safetensors:  36%|███▌      | 00:16<00:17,  3.61it/s\n",
      "Loading weights: model.safetensors:  37%|███▋      | 00:16<00:17,  3.68it/s\n",
      "Loading weights: model.safetensors:  38%|███▊      | 00:16<00:15,  4.09it/s\n",
      "Loading weights: model.safetensors:  38%|███▊      | 00:17<00:21,  2.88it/s\n",
      "Loading weights: model.safetensors:  40%|████      | 00:17<00:16,  3.65it/s\n",
      "Loading weights: model.safetensors:  41%|████      | 00:17<00:18,  3.18it/s\n",
      "Loading weights: model.safetensors:  43%|████▎     | 00:18<00:16,  3.58it/s\n",
      "Loading weights: model.safetensors:  43%|████▎     | 00:18<00:18,  3.09it/s\n",
      "Loading weights: model.safetensors:  45%|████▍     | 00:18<00:13,  4.07it/s\n",
      "Loading weights: model.safetensors:  45%|████▌     | 00:19<00:15,  3.51it/s\n",
      "Loading weights: model.safetensors:  46%|████▌     | 00:19<00:14,  3.61it/s\n",
      "Loading weights: model.safetensors:  47%|████▋     | 00:19<00:12,  4.15it/s\n",
      "Loading weights: model.safetensors:  48%|████▊     | 00:20<00:23,  2.18it/s\n",
      "Loading weights: model.safetensors:  48%|████▊     | 00:20<00:21,  2.39it/s\n",
      "Loading weights: model.safetensors:  50%|████▉     | 00:20<00:18,  2.71it/s\n",
      "Loading weights: model.safetensors:  50%|█████     | 00:20<00:20,  2.42it/s\n",
      "Loading weights: model.safetensors:  52%|█████▏    | 00:21<00:13,  3.58it/s\n",
      "Loading weights: model.safetensors:  52%|█████▏    | 00:21<00:19,  2.48it/s\n",
      "Loading weights: model.safetensors:  53%|█████▎    | 00:22<00:19,  2.44it/s\n",
      "Loading weights: model.safetensors:  54%|█████▍    | 00:22<00:16,  2.77it/s\n",
      "Loading weights: model.safetensors:  55%|█████▍    | 00:23<00:24,  1.81it/s\n",
      "Loading weights: model.safetensors:  55%|█████▌    | 00:23<00:25,  1.78it/s\n",
      "Loading weights: model.safetensors:  55%|█████▌    | 00:23<00:24,  1.82it/s\n",
      "Loading weights: model.safetensors:  57%|█████▋    | 00:24<00:23,  1.84it/s\n",
      "Loading weights: model.safetensors:  57%|█████▋    | 00:24<00:29,  1.43it/s\n",
      "Loading weights: model.safetensors:  58%|█████▊    | 00:25<00:27,  1.52it/s\n",
      "Loading weights: model.safetensors:  58%|█████▊    | 00:25<00:23,  1.76it/s\n",
      "Loading weights: model.safetensors:  60%|█████▉    | 00:25<00:14,  2.81it/s\n",
      "Loading weights: model.safetensors:  61%|██████    | 00:25<00:08,  4.36it/s\n",
      "Loading weights: model.safetensors:  62%|██████▏   | 00:25<00:08,  4.71it/s\n",
      "Loading weights: model.safetensors:  63%|██████▎   | 00:25<00:06,  5.55it/s\n",
      "Loading weights: model.safetensors:  64%|██████▍   | 00:25<00:06,  5.78it/s\n",
      "Loading weights: model.safetensors:  65%|██████▍   | 00:26<00:06,  5.81it/s\n",
      "Loading weights: model.safetensors:  66%|██████▌   | 00:26<00:05,  6.35it/s\n",
      "Loading weights: model.safetensors:  67%|██████▋   | 00:26<00:04,  6.91it/s\n",
      "Loading weights: model.safetensors:  68%|██████▊   | 00:26<00:04,  6.96it/s\n",
      "Loading weights: model.safetensors:  69%|██████▉   | 00:26<00:04,  6.68it/s\n",
      "Loading weights: model.safetensors:  70%|██████▉   | 00:26<00:04,  6.70it/s\n",
      "Loading weights: model.safetensors:  71%|███████   | 00:26<00:04,  6.31it/s\n",
      "Loading weights: model.safetensors:  72%|███████▏  | 00:27<00:04,  6.63it/s\n",
      "Loading weights: model.safetensors: 100%|██████████| 00:28<00:00, 19.01it/s\n",
      "Loading weights: model.safetensors: 100%|██████████| 00:28<00:00,  3.54it/s\n"
     ]
    }
   ],
   "source": [
    "!litgpt download microsoft/phi-1_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630f531",
   "metadata": {},
   "source": [
    "Step 4. Use the Model in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1ea70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litgpt import LLM\n",
    "\n",
    "# Load the model (ensure it’s downloaded first)\n",
    "llm = LLM.load(\"microsoft/phi-1_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99deffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The llama's diet is primarily plant-based.\n",
      "\n",
      "Exercise 4: What do oxen use for plowing?\n",
      "\n",
      "Answer: Oxen are often used for plowing to make it easier to till the soil.\n",
      "\n",
      "Ex\n"
     ]
    }
   ],
   "source": [
    "# Simple text generation\n",
    "output = llm.generate(\"What do llamas eat?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda23cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI has a long and fascinating history that dates back to the 1950s and 60s, when the field of artificial intelligence was first introduced by researchers and scholars in fields such as computer science and philosophy. Some of the key milestones and events that shaped the development of AI in the modern era include the introduction of AI chatbots and virtual assistants like Siri and Alexa, advances in machine learning and natural language processing, and the rise of deep reinforcement learning and neural networks. In recent years, AI has continued to"
     ]
    }
   ],
   "source": [
    "# Streamed output (prints as it generates)\n",
    "for token in llm.generate(\"Tell me about the history of AI.\", stream=True, max_new_tokens=100):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44a5f3",
   "metadata": {},
   "source": [
    "Step 5. Try Chat Mode (Terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e72515",
   "metadata": {},
   "source": [
    "* Since microsoft/phi-2 or phi-1_5 is larger model for my terminal. I have used **HuggingFaceTB/SmolLM2-135M-Instruct**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda6698",
   "metadata": {},
   "source": [
    "![ChatMode(Terminal)](<../images/ChatMode(Terminal).png>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
